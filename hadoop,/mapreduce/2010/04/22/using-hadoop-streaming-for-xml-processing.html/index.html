
<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>Using Hadoop Streaming for XML processing - Steve Eichert</title>
  <meta name="author" content="Steve Eichert">

  
  <meta name="description" content="In a few previous posts I talked about a project that we&#8217;re working on that involves analyzing a lot of XML documents from pubmed. We&#8217;re &hellip;">
  

  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  
  <link rel="canonical" href="http://steveeichert.com/hadoop,/mapreduce/2010/04/22/using-hadoop-streaming-for-xml-processing.html">
  <link href="/favicon.png" rel="icon">
  <link href="/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
  <script src="/javascripts/modernizr-2.0.js"></script>
  <script src="/javascripts/ender.js"></script>
  <script src="/javascripts/octopress.js" type="text/javascript"></script>
  <link href="/atom.xml" rel="alternate" title="Steve Eichert" type="application/atom+xml">
  <!--Fonts from Google"s Web font directory at http://google.com/webfonts -->
<link href="http://fonts.googleapis.com/css?family=PT+Serif:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">
<link href="http://fonts.googleapis.com/css?family=PT+Sans:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">

  

</head>

<body   >
  <header role="banner"><hgroup>
  <h1><a href="/">Steve Eichert</a></h1>
  
    <h2>Hacker, Entreprenuer, Father</h2>
  
</hgroup>

</header>
  <nav role="navigation"><ul class="subscription" data-subscription="rss">
  <li><a href="/atom.xml" rel="subscribe-rss" title="subscribe via RSS">RSS</a></li>
  
</ul>
  
<form action="http://google.com/search" method="get">
  <fieldset role="search">
    <input type="hidden" name="q" value="site:steveeichert.com" />
    <input class="search" type="text" name="q" results="0" placeholder="Search"/>
  </fieldset>
</form>
  
<ul class="main-navigation">
  <li><a href="/">Blog</a></li>
  <li><a href="/blog/archives">Archives</a></li>
</ul>

</nav>
  <div id="main">
    <div id="content">
      <div>
<article class="hentry" role="article">
  
  <header>
    
      <h1 class="entry-title">Using Hadoop Streaming for XML Processing</h1>
    
    
      <p class="meta">
        








  


<time datetime="2010-04-22T00:00:00-04:00" pubdate data-updated="true">Apr 22<span>nd</span>, 2010</time>
        
      </p>
    
  </header>


<div class="entry-content"><p>In a few previous posts I talked about a project that we&#8217;re working on that involves analyzing a lot of <span class="caps">XML</span> documents from pubmed.  We&#8217;re currently not using Hadoop to parse the raw <span class="caps">XML</span>, however, due to the large number of documents in pubmed and the time it takes to do the parsing we&#8217;ve been discussing options that would allow us to scale up the processing to happen on multiple machines.  Since we&#8217;re already using Hadoop for analysis I decided to poke around a bit to see if we could figure out a way to use Hadoop for the parsing of the 617+ <span class="caps">XML</span> documents.</p>
<p>After some digging I came across <a href="http://hadoop.apache.org/common/docs/r0.15.2/streaming.html#How+do+I+parse+XML+documents+using+streaming%3F">this page</a> on the Hadoop Streaming page that said the following: &#8220;You can use the record reader StreamXmlRecordReader to process <span class="caps">XML</span> documents&#8230;.Anything found between BEGIN_STRING and END_STRING would be treated as one record for map tasks.&#8221;</p>
<p>After a few tries I wasn&#8217;t having much success, so continued to look for alternate options.  I came across Paul Ingles post on <a href="http://oobaloo.co.uk/articles/2010/1/20/processing-xml-in-hadoop.html">Processing <span class="caps">XML</span> with Hadoop</a> which pointed me to the <a href="http://github.com/apache/mahout/blob/ad84344e4055b1e6adff5779339a33fa29e1265d/examples/src/main/java/org/apache/mahout/classifier/bayes/XmlInputFormat.java">XmlInputFormat</a> class in Mahout.  I believe in order to use the XlInputFormat class from Mahout I either need to recompile Hadoop with that class included or be using a jar file for my jobs that includes that class.  Since we&#8217;re writing our mappers and reducers in Ruby I didn&#8217;t have a jar to add the class to.</p>
<p>In hopes that I was being stupid with the StreamXmlReaderRecord I decided to return to it and attempt to get it working.  After configuring it I saw some positive things in the console as I ran my job.  It did in fact look like Hadoop was breaking apart my <span class="caps">XML</span> documents into the appropriate chunks (using the start and end tags I specified in my config)</p>
<div class='bogus-wrapper'><figure class='code'><figcaption><span><figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span><br />
<span class='line-number'>2</span><br />
<span class='line-number'>3</span><br />
<span class='line-number'>4</span><br />
<span class='line-number'>5</span><br />
<span class='line-number'>6</span><br />
</pre></td><td class='code'><pre><code class='ruby'>&lt;span class='line'&gt;&lt;span class="n"&gt;hadoop&lt;/span&gt; &lt;span class="n"&gt;jar&lt;/span&gt; &lt;span class="n"&gt;hadoop&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="mi"&gt;20&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;streaming&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;jar&lt;/span&gt;
&lt;/span&gt;&lt;span class='line'&gt;   &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;input&lt;/span&gt; &lt;span class="n"&gt;medline10n0515&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;xml&lt;/span&gt;
&lt;/span&gt;&lt;span class='line'&gt;   &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;output&lt;/span&gt; &lt;span class="n"&gt;out&lt;/span&gt;
&lt;/span&gt;&lt;span class='line'&gt;   &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;mapper&lt;/span&gt; &lt;span class="n"&gt;xml&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;mapper&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;rb&lt;/span&gt;
&lt;/span&gt;&lt;span class='line'&gt;   &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;inputreader&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;StreamXmlRecordReader,begin=&amp;lt;MedlineCitation,end=&amp;lt;/MedlineCitation&amp;gt;&amp;quot;&lt;/span&gt;
&lt;/span&gt;&lt;span class='line'&gt;   &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;jobconf&lt;/span&gt; &lt;span class="n"&gt;mapred&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;reduce&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;tasks&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;
&lt;/span&gt;</code></pre></td><p></tr></table></div></figure></notextile></div></p>
<p>The next thing to figure out was how I should be retrieving the entire <span class="caps">XML</span> contents from within my mapper.  With Hadoop Streaming the input is streamed in via <span class="caps">STDIN</span> so I attempted building up the <span class="caps">XML</span> myself using some mega-smart &#8220;parse&#8221; logic!</p>
<div class='bogus-wrapper'><figure class='code'><figcaption><span><figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span><br />
<span class='line-number'>2</span><br />
<span class='line-number'>3</span><br />
<span class='line-number'>4</span><br />
<span class='line-number'>5</span><br />
<span class='line-number'>6</span><br />
<span class='line-number'>7</span><br />
<span class='line-number'>8</span><br />
<span class='line-number'>9</span><br />
<span class='line-number'>10</span><br />
<span class='line-number'>11</span><br />
<span class='line-number'>12</span><br />
<span class='line-number'>13</span><br />
<span class='line-number'>14</span><br />
<span class='line-number'>15</span><br />
</pre></td><td class='code'><pre><code class='ruby'>&lt;span class='line'&gt;&lt;span class="c1"&gt;#!/usr/bin/env ruby&lt;/span&gt;
&lt;/span&gt;&lt;span class='line'&gt;&lt;span class="n"&gt;xml&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="kp"&gt;nil&lt;/span&gt;
&lt;/span&gt;&lt;span class='line'&gt;&lt;span class="no"&gt;STDIN&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;each_line&lt;/span&gt; &lt;span class="k"&gt;do&lt;/span&gt; &lt;span class="o"&gt;|&lt;/span&gt;&lt;span class="n"&gt;line&lt;/span&gt;&lt;span class="o"&gt;|&lt;/span&gt;
&lt;/span&gt;&lt;span class='line'&gt;  &lt;span class="n"&gt;line&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;strip!&lt;/span&gt;
&lt;/span&gt;&lt;span class='line'&gt;
&lt;/span&gt;&lt;span class='line'&gt;  &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;line&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;include?&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&amp;lt;MedlineCitation&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;span class='line'&gt;    &lt;span class="n"&gt;xml&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;line&lt;/span&gt;
&lt;/span&gt;&lt;span class='line'&gt;  &lt;span class="k"&gt;else&lt;/span&gt;
&lt;/span&gt;&lt;span class='line'&gt;    &lt;span class="n"&gt;xml&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="n"&gt;line&lt;/span&gt;
&lt;/span&gt;&lt;span class='line'&gt;  &lt;span class="k"&gt;end&lt;/span&gt;
&lt;/span&gt;&lt;span class='line'&gt;
&lt;/span&gt;&lt;span class='line'&gt;  &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;line&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;include?&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&amp;lt;/MedlineCitation&amp;gt;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;span class='line'&gt;    &lt;span class="nb"&gt;puts&lt;/span&gt; &lt;span class="n"&gt;convert_to_json&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;xml&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;span class='line'&gt;  &lt;span class="k"&gt;end&lt;/span&gt;
&lt;/span&gt;&lt;span class='line'&gt;&lt;span class="k"&gt;end&lt;/span&gt;
&lt;/span&gt;</code></pre></td><p></tr></table></div></figure></notextile></div></p>
<p>As you can see I look for the start and end tags relevant for my <span class="caps">XML</span>, and once I have a complete document I pass the <span class="caps">XML</span> to the convert_to_json method.  There&#8217;s definitely quite a bit of cleanup that can be done, as well as edge cases that aren&#8217;t handled (nested tags that match the root tag), but we&#8217;ve at least co-erced Hadoop into doing what we want.  Next up is seeing how well it works when run against the entire dataset.</p></div>


  <footer>
    <p class="meta">
      
  

<span class="byline author vcard">Posted by <span class="fn">Steve Eichert</span></span>

      








  


<time datetime="2010-04-22T00:00:00-04:00" pubdate data-updated="true">Apr 22<span>nd</span>, 2010</time>
      

<span class="categories">
  
    <a class='category' href='/blog/categories/hadoop-/'>hadoop,</a>, <a class='category' href='/blog/categories/mapreduce/'>mapreduce</a>
  
</span>


    </p>
    
      <div class="sharing">
  
  <a href="http://twitter.com/share" class="twitter-share-button" data-url="http://steveeichert.com/hadoop,/mapreduce/2010/04/22/using-hadoop-streaming-for-xml-processing.html" data-via="steveeichert" data-counturl="http://steveeichert.com/hadoop,/mapreduce/2010/04/22/using-hadoop-streaming-for-xml-processing.html" >Tweet</a>
  
  
  <div class="g-plusone" data-size="medium"></div>
  
  
    <div class="fb-like" data-send="true" data-width="450" data-show-faces="false"></div>
  
</div>

    
    <p class="meta">
      
        <a class="basic-alignment left" href="/2010/03/31/data-analysis-using-mongodb-map-reduce.html" title="Previous Post: Attempts at Analyzing 19 million documents using MongoDB map/reduce">&laquo; Attempts at Analyzing 19 million documents using MongoDB map/reduce</a>
      
      
    </p>
  </footer>
</article>

</div>

<aside class="sidebar">
  
    <section>
  <h1>Recent Posts</h1>
  <ul id="recent_posts">
    
      <li class="post">
        <a href="/hadoop,/mapreduce/2010/04/22/using-hadoop-streaming-for-xml-processing.html">Using Hadoop Streaming for XML processing</a>
      </li>
    
      <li class="post">
        <a href="/2010/03/31/data-analysis-using-mongodb-map-reduce.html">Attempts at Analyzing 19 million documents using MongoDB map/reduce</a>
      </li>
    
      <li class="post">
        <a href="/2010/03/18/large-scale-data-processing-with-mongodb.html">Large Scale Data Processing with MongoDB Map/Reduce (Part 1:Background)</a>
      </li>
    
      <li class="post">
        <a href="/2009/01/30/network-visualization-on-the-web.html">Network Visualization on the Web</a>
      </li>
    
      <li class="post">
        <a href="/2008/12/28/moving-gems-from-one-version-of-ree-to-another.html">Moving Gems from one version of Ruby Enterprise Edition to Another</a>
      </li>
    
  </ul>
</section>


<section>
  <h1>Latest Tweets</h1>
  <ul id="tweets">
    <li class="loading">Status updating...</li>
  </ul>
  <script type="text/javascript">
    $.domReady(function(){
      getTwitterFeed("steveeichert", 4, false);
    });
  </script>
  <script src="/javascripts/twitter.js" type="text/javascript"> </script>
  
    <a href="http://twitter.com/steveeichert" class="twitter-follow-button" data-show-count="false">Follow @steveeichert</a>
  
</section>





  
</aside>


    </div>
  </div>
  <footer role="contentinfo"><p>
  Copyright &copy; 2012 - Steve Eichert -
  <span class="credit">Powered by <a href="http://octopress.org">Octopress</a></span>
</p>

</footer>
  

<script type="text/javascript">
      var disqus_shortname = 'steveeichert';
      
        
        var disqus_script = 'count.js';
      
    (function () {
      var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
      dsq.src = 'http://' + disqus_shortname + '.disqus.com/' + disqus_script;
      (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    }());
</script>



<div id="fb-root"></div>
<script>(function(d, s, id) {
  var js, fjs = d.getElementsByTagName(s)[0];
  if (d.getElementById(id)) {return;}
  js = d.createElement(s); js.id = id;
  js.src = "//connect.facebook.net/en_US/all.js#appId=212934732101925&xfbml=1";
  fjs.parentNode.insertBefore(js, fjs);
}(document, 'script', 'facebook-jssdk'));</script>



  <script type="text/javascript">
    (function() {
      var script = document.createElement('script'); script.type = 'text/javascript'; script.async = true;
      script.src = 'https://apis.google.com/js/plusone.js';
      var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(script, s);
    })();
  </script>



  <script type="text/javascript">
    (function(){
      var twitterWidgets = document.createElement('script');
      twitterWidgets.type = 'text/javascript';
      twitterWidgets.async = true;
      twitterWidgets.src = 'http://platform.twitter.com/widgets.js';
      document.getElementsByTagName('head')[0].appendChild(twitterWidgets);
    })();
  </script>





</body>
</html>
