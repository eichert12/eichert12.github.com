
<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>Using Hadoop Streaming for XML processing - Steve Eichert</title>
  <meta name="author" content="Steve Eichert">

  
  <meta name="description" content="In a few previous posts I talked about a project that we&#8217;re working on that involves analyzing a lot of XML documents from pubmed. We&#8217;re &hellip;">
  

  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  
  <link rel="canonical" href="http://steveeichert.com/hadoop,/mapreduce/2010/04/22/using-hadoop-streaming-for-xml-processing.html">
  <link href="/favicon.png" rel="icon">
  <link href="/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
  <script src="/javascripts/modernizr-2.0.js"></script>
  <script src="/javascripts/ender.js"></script>
  <script src="/javascripts/octopress.js" type="text/javascript"></script>
  <link href="/atom.xml" rel="alternate" title="Steve Eichert" type="application/atom+xml">
  <!--Fonts from Google"s Web font directory at http://google.com/webfonts -->
<link href="http://fonts.googleapis.com/css?family=PT+Serif:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">
<link href="http://fonts.googleapis.com/css?family=PT+Sans:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">

  

</head>

<body   >
  <header role="banner"><hgroup>
  <h1><a href="/">Steve Eichert</a></h1>
  
    <h2>Hacker, Entreprenuer, Father</h2>
  
</hgroup>

</header>
  <nav role="navigation"><ul class="subscription" data-subscription="rss">
  <li><a href="/atom.xml" rel="subscribe-rss" title="subscribe via RSS">RSS</a></li>
  
</ul>
  
<form action="http://google.com/search" method="get">
  <fieldset role="search">
    <input type="hidden" name="q" value="site:steveeichert.com" />
    <input class="search" type="text" name="q" results="0" placeholder="Search"/>
  </fieldset>
</form>
  
<ul class="main-navigation">
  <li><a href="/">Blog</a></li>
  <li><a href="/blog/archives">Archives</a></li>
</ul>

</nav>
  <div id="main">
    <div id="content">
      <div>
<article class="hentry" role="article">
  
  <header>
    
      <h1 class="entry-title">Using Hadoop Streaming for XML Processing</h1>
    
    
      <p class="meta">
        








  


<time datetime="2010-04-22T00:00:00-04:00" pubdate data-updated="true">Apr 22<span>nd</span>, 2010</time>
        
      </p>
    
  </header>


<div class="entry-content"><p>In a few previous posts I talked about a project that we&#8217;re working on that involves analyzing a lot of XML documents from pubmed.  We&#8217;re currently not using Hadoop to parse the raw XML, however, due to the large number of documents in pubmed and the time it takes to do the parsing we&#8217;ve been discussing options that would allow us to scale up the processing to happen on multiple machines.  Since we&#8217;re already using Hadoop for analysis I decided to poke around a bit to see if we could figure out a way to use Hadoop for the parsing of the 617+ XML documents.</p>

<p>After some digging I came across <a href="http://hadoop.apache.org/common/docs/r0.15.2/streaming.html#How+do+I+parse+XML+documents+using+streaming%3F">this page</a> on the Hadoop Streaming page that said the following: &#8220;You can use the record reader StreamXmlRecordReader to process XML documents&#8230;.Anything found between BEGIN_STRING and END_STRING would be treated as one record for map tasks.&#8221;</p>

<p>After a few tries I wasn&#8217;t having much success, so continued to look for alternate options.  I came across Paul Ingles post on <a href="http://oobaloo.co.uk/articles/2010/1/20/processing-xml-in-hadoop.html">Processing XML with Hadoop</a> which pointed me to the <a href="http://github.com/apache/mahout/blob/ad84344e4055b1e6adff5779339a33fa29e1265d/examples/src/main/java/org/apache/mahout/classifier/bayes/XmlInputFormat.java">XmlInputFormat</a> class in Mahout.  I believe in order to use the XlInputFormat class from Mahout I either need to recompile Hadoop with that class included or be using a jar file for my jobs that includes that class.  Since we&#8217;re writing our mappers and reducers in Ruby I didn&#8217;t have a jar to add the class to.</p>

<p>In hopes that I was being stupid with the StreamXmlReaderRecord I decided to return to it and attempt to get it working.  After configuring it I saw some positive things in the console as I ran my job.  It did in fact look like Hadoop was breaking apart my XML documents into the appropriate chunks (using the start and end tags I specified in my config)</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>hadoop jar hadoop-0.20.2-streaming.jar 
</span><span class='line'>   -input medline10n0515.xml 
</span><span class='line'>   -output out 
</span><span class='line'>   -mapper xml-mapper.rb 
</span><span class='line'>   -inputreader "StreamXmlRecordReader,begin=&lt;MedlineCitation,end=&lt;/MedlineCitation&gt;" 
</span><span class='line'>   -jobconf mapred.reduce.tasks=0</span></code></pre></td></tr></table></div></figure>


<p>The next thing to figure out was how I should be retrieving the entire XML contents from within my mapper.  With Hadoop Streaming the input is streamed in via STDIN so I attempted building up the XML myself using some mega-smart &#8220;parse&#8221; logic!</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
</pre></td><td class='code'><pre><code class='ruby'><span class='line'><span class="c1">#!/usr/bin/env ruby</span>
</span><span class='line'><span class="n">xml</span> <span class="o">=</span> <span class="kp">nil</span>
</span><span class='line'><span class="no">STDIN</span><span class="o">.</span><span class="n">each_line</span> <span class="k">do</span> <span class="o">|</span><span class="n">line</span><span class="o">|</span>
</span><span class='line'>  <span class="n">line</span><span class="o">.</span><span class="n">strip!</span>
</span><span class='line'>
</span><span class='line'>  <span class="k">if</span> <span class="n">line</span><span class="o">.</span><span class="n">include?</span><span class="p">(</span><span class="s2">&quot;&lt;MedlineCitation&quot;</span><span class="p">)</span>
</span><span class='line'>    <span class="n">xml</span> <span class="o">=</span> <span class="n">line</span>
</span><span class='line'>  <span class="k">else</span>
</span><span class='line'>    <span class="n">xml</span> <span class="o">+=</span> <span class="n">line</span>
</span><span class='line'>  <span class="k">end</span>
</span><span class='line'>
</span><span class='line'>  <span class="k">if</span> <span class="n">line</span><span class="o">.</span><span class="n">include?</span><span class="p">(</span><span class="s2">&quot;&lt;/MedlineCitation&gt;&quot;</span><span class="p">)</span>
</span><span class='line'>    <span class="nb">puts</span> <span class="n">convert_to_json</span><span class="p">(</span><span class="n">xml</span><span class="p">)</span>
</span><span class='line'>  <span class="k">end</span>
</span><span class='line'><span class="k">end</span>
</span></code></pre></td></tr></table></div></figure>


<p>As you can see I look for the start and end tags relevant for my XML, and once I have a complete document I pass the XML to the convert_to_json method.  There&#8217;s definitely quite a bit of cleanup that can be done, as well as edge cases that aren&#8217;t handled (nested tags that match the root tag), but we&#8217;ve at least co-erced Hadoop into doing what we want.  Next up is seeing how well it works when run against the entire dataset.</p>
</div>


  <footer>
    <p class="meta">
      
  

<span class="byline author vcard">Posted by <span class="fn">Steve Eichert</span></span>

      








  


<time datetime="2010-04-22T00:00:00-04:00" pubdate data-updated="true">Apr 22<span>nd</span>, 2010</time>
      

<span class="categories">
  
    <a class='category' href='/blog/categories/hadoop-/'>hadoop,</a>, <a class='category' href='/blog/categories/mapreduce/'>mapreduce</a>
  
</span>


    </p>
    
      <div class="sharing">
  
  <a href="http://twitter.com/share" class="twitter-share-button" data-url="http://steveeichert.com/hadoop,/mapreduce/2010/04/22/using-hadoop-streaming-for-xml-processing.html" data-via="steveeichert" data-counturl="http://steveeichert.com/hadoop,/mapreduce/2010/04/22/using-hadoop-streaming-for-xml-processing.html" >Tweet</a>
  
  
  
    <div class="fb-like" data-send="true" data-width="450" data-show-faces="false"></div>
  
</div>

    
    <p class="meta">
      
        <a class="basic-alignment left" href="/2010/03/31/data-analysis-using-mongodb-map-reduce.html" title="Previous Post: Attempts at Analyzing 19 million documents using MongoDB map/reduce">&laquo; Attempts at Analyzing 19 million documents using MongoDB map/reduce</a>
      
      
        <a class="basic-alignment right" href="/blog/2012/02/10/creating/" title="next Post: Creating">Creating &raquo;</a>
      
    </p>
  </footer>
</article>

  <section>
    <h1>Comments</h1>
    <div id="disqus_thread" aria-live="polite"><noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
</div>
  </section>

</div>

<aside class="sidebar">
  
    <section>
  <h1>Recent Posts</h1>
  <ul id="recent_posts">
    
      <li class="post">
        <a href="/blog/2012/02/13/how-not-to-choose-a-business-partner-or-co-founder/">Don't be the 'Idea Guy'</a>
      </li>
    
      <li class="post">
        <a href="/blog/2012/02/12/consumption/">Consumption Kills</a>
      </li>
    
      <li class="post">
        <a href="/blog/2012/02/10/creating/">Creating</a>
      </li>
    
      <li class="post">
        <a href="/hadoop,/mapreduce/2010/04/22/using-hadoop-streaming-for-xml-processing.html">Using Hadoop Streaming for XML processing</a>
      </li>
    
      <li class="post">
        <a href="/2010/03/31/data-analysis-using-mongodb-map-reduce.html">Attempts at Analyzing 19 million documents using MongoDB map/reduce</a>
      </li>
    
  </ul>
</section>


<section>
  <h1>Latest Tweets</h1>
  <ul id="tweets">
    <li class="loading">Status updating...</li>
  </ul>
  <script type="text/javascript">
    $.domReady(function(){
      getTwitterFeed("steveeichert", 4, false);
    });
  </script>
  <script src="/javascripts/twitter.js" type="text/javascript"> </script>
  
    <a href="http://twitter.com/steveeichert" class="twitter-follow-button" data-show-count="false">Follow @steveeichert</a>
  
</section>





  
</aside>


    </div>
  </div>
  <footer role="contentinfo"><p>
  Copyright &copy; 2012 - Steve Eichert -
  <span class="credit">Powered by <a href="http://octopress.org">Octopress</a></span>
</p>

</footer>
  

<script type="text/javascript">
      var disqus_shortname = 'steveeichert';
      
        
        // var disqus_developer = 1;
        var disqus_identifier = 'http://steveeichert.com/hadoop,/mapreduce/2010/04/22/using-hadoop-streaming-for-xml-processing.html';
        var disqus_url = 'http://steveeichert.com/hadoop,/mapreduce/2010/04/22/using-hadoop-streaming-for-xml-processing.html';
        var disqus_script = 'embed.js';
      
    (function () {
      var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
      dsq.src = 'http://' + disqus_shortname + '.disqus.com/' + disqus_script;
      (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    }());
</script>



<div id="fb-root"></div>
<script>(function(d, s, id) {
  var js, fjs = d.getElementsByTagName(s)[0];
  if (d.getElementById(id)) {return;}
  js = d.createElement(s); js.id = id;
  js.src = "//connect.facebook.net/en_US/all.js#appId=212934732101925&xfbml=1";
  fjs.parentNode.insertBefore(js, fjs);
}(document, 'script', 'facebook-jssdk'));</script>





  <script type="text/javascript">
    (function(){
      var twitterWidgets = document.createElement('script');
      twitterWidgets.type = 'text/javascript';
      twitterWidgets.async = true;
      twitterWidgets.src = 'http://platform.twitter.com/widgets.js';
      document.getElementsByTagName('head')[0].appendChild(twitterWidgets);
    })();
  </script>





</body>
</html>
